# -*- coding: utf-8 -*-
"""
Spyder Editor

This is a temporary script file.
"""

import pandas as pd
#import numpy as np
import streamlit as st
import matplotlib.pyplot as plt
import seaborn as sns
#from datetime import datetime as dt
#import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder
#from imblearn.over_sampling import RandomOverSampler
#from sklearn.compose import ColumnTransformer
#from sklearn.impute import SimpleImputer
#from plotly.subplots import make_subplots
import plotly.express as px
import joblib
#from sklearn.metrics import f1_score

df=pd.read_csv('C:/Users/famil/ProjetKickStarter/Kickstarter Campaigns DataSet.csv')



st.sidebar.title('Sommaire')

pages = ['Pr√©sentation','Exploration des Donn√©es','Analyse des donn√©es','Mod√©lisation','Application','Conclusion']
page = st.sidebar.radio('allez vers la page', pages)


#***************************************************************************************************
#***************************************************************************************************
# PAGE 0 Pr√©sentation
#***************************************************************************************************
#***************************************************************************************************

if page == pages[0]:
    st.title("Prediction du succ√®s d'une campagne de financement participatif")
    st.write(" Contexte du Projet")
    st.write("Une campagne participative ou crowdfunding c‚Äôest un moyen de collecte de fonds en ligne pour soutenir le d√©veloppement d‚Äôun projet, qu‚Äôil s‚Äôagisse de la cr√©ation d‚Äôune entreprise, d‚Äôun documentaire, d‚Äôun film, etc.")
    st.write("Arr√™tons-nous au plus grand succ√®s du crowfunding ¬´ star citizen ¬ª un jeu vid√©o avec 300 millions de dollar r√©colt√© ou la marque ¬´ Humble ¬ª avec une campagne r√©ussi sur un smoothie prot√©in√©. On peut se demander ce qui a fait le succ√®s de leur campagne.")
    st.write("Le financement alternatif, tel que le crowfunding en ligne, est souvent plus attrayant qu‚Äôun pr√™t bancaire pour concr√©tiser une id√©e. Toutefois, la r√©alisation d‚Äôune campagne de crowdfunding est cruciale pour d√©terminer si un projet va d√©coller ou non.")
    st.write("L'objectif de ce projet est de comprendre les cl√©s de la r√©ussite d‚Äôune campagne de financement participatif, en classant les projets en r√©ussite ou √©chec, puis en analysant les raisons potentielles de ces r√©sultats.")
    st.write("Cela permettra de guider les cr√©ateurs dans la mise en place de leur campagne et de prendre des d√©cisions √©clair√©es concernant son lancement.")
    st.image("Crowfounding2.jpg")

#***************************************************************************************************
#***************************************************************************************************
# PAGE 1 Exploration des donn√©es

#***************************************************************************************************
#***************************************************************************************************

elif page ==pages[1]:
    st.title("  Exploration des donn√©es")
    st.write("Le jeu de donn√©es utilis√© a √©t√© obtenu gr√¢ce au webscraping de Kickstarter provenant de webro-bots.io ( https://webrobots.io/kickstarter-datasets/). Les donn√©es ont √©t√© combin√©es, pr√©trait√©es et mise √† disposition dans un jeu de donn√©es contenant des projets(campagnes) de 2009 √† 2020. Ce jeu de donn√©es est disponible sur le site https://www.kaggle.com/datasets/yashkantharia/kickstarter-campaigns-dataset-20")
    
    st.write("Aper√ßu des donn√©es")
    st.dataframe(df.head())
    
    st.write("Dimensions initial du Dataframe:")
    st.write(df.shape)
    st.write("Type des donn√©es:")
    st.write(df.dtypes)
    
    # nombre des donn√©es par status
    
    functions_to_apply = {
        'id' : lambda x: len(x)
    }
    testStatus=df.groupby('status').agg(functions_to_apply)
    st.write("nombre des donn√©es par status:")
    st.write(testStatus)
    
    df = df[(df['status']=='successful') | (df['status']=='failed')]
    st.write("Total de campagnes successful et failed:")
    st.write(len(df))
    
    
    # valeurs manquantes

    if st.checkbox("Aficher les valeurs manquantes"):
       st.dataframe(df.isna().sum())

    # examiner les doublons

    #print('nombre de doublons: ',df.duplicated().sum(),'\n')

    # √©liminer la colonne Unnamed: 0

    df.drop(columns=["Unnamed: 0"],inplace=True)
    if st.checkbox("Aficher les doublons"):
       st.write(df.duplicated().sum())

    #print('nombre de doublons sans colonne Unnamed: 0 : ',df.duplicated().sum(),'\n')

    # √©liminer les doublons

    df = df.drop_duplicates(keep='first') 
    #print('Total de campagnes successful et failed sans doublons: ', len(df),'\n')

    # Changement nom des colonnes

    df = df.rename({'sub_category':'category', }, axis = 1)
    #print(df['category'].unique(),'\n')

    df = df.rename({'main_category':'sub_category'}, axis = 1)
   # print(df['sub_category'].unique(),'\n')

    # changement du type de colonne

    #print(type(df['launched_at'][0]),'\n')

    df['launched_at'] = pd.to_datetime(df['launched_at'])

    #print(type(df['deadline'][0]),'\n')

    df['deadline'] = pd.to_datetime(df['deadline'])

    df['duration'] = df['duration'].astype('int') 

    # cr√©ation des colonnes

    df['year_launched'] = df['launched_at'].dt.year
    df['month_launched'] = df['launched_at'].dt.month

    df['year_deadline'] = df['deadline'].dt.year
    df['month_deadline'] = df['deadline'].dt.month

    st.write("Traitement fait au niveau des donn√©es:")
    st.write("‚Ä¢ √âlimination des doublons ")
    st.write("‚Ä¢	Changement du nom des colonnes : la colonne ¬´ sub_category ¬ª par ¬´ category ¬ª et ¬´ main_category ¬ª par ¬´ sub_category ¬ª")
    st.write("‚Ä¢	Changement de type de colonnes : Le type des variables dates(str) ont √©t√© modifi√©s au type date, le type de la variable duration(float) a √©t√© modifi√© au type int")
    st.write("‚Ä¢	Cr√©ation des colonnes : √Ä partir des colonnes de type dates quatre nouvelles colonnes ann√©e et mois ont √©t√© cr√©√©es")
    if st.checkbox("Nombre total des donn√©es apr√®s Nettoyage:"):
       st.write(len(df))
    
    st.dataframe(df.dtypes)
    st.write("##### Aper√ßu statistique")
    st.dataframe(df.describe())

#***************************************************************************************************
#***************************************************************************************************
# PAGE 2 ANALYSE DES DONNEES

#***************************************************************************************************
#***************************************************************************************************
       
elif page == pages[2]:
    st.title("  Analyse des donn√©es")
    st.write("L‚Äôanalyse servira √† d√©crire et r√©sumer des donn√©es de mani√®re significative afin de tirer des informations.")
    st.write("Il s‚Äôagit tout d'abord de savoir quel est le nombre des campagnes r√©ussies et le nombre des campagnes √©chou√©es √† l‚Äôaide de la variable aidant √† trouver la r√©ponse ¬´ status ¬ª. Sur un total de 184899 donn√©es il y a 109205 r√©ussies et 75694 √©chou√©es.")
    df_clean = pd.read_csv("df_Cleaning.csv")
     
    st.write("Pourcentage des campagnes par status")
    st.image("CampagneStatus.jpg")
 
    
    st.write("L‚Äôanalyse portera sur 4 axes : ‚Ä¢	Cat√©gorie ‚Ä¢	Finance ‚Ä¢G√©ographique ‚Ä¢Temps ")
    
# Radio button pour les axes
#----------------------------

    page_names = ['Cat√©gorie', 'Finance', 'G√©ographique', 'Temps']
    page2 = st.radio('Navigation', page_names)

#        Axe Cat√©gorie
#****************************
    
    if page2 == page_names[0]:
        st.subheader("Axe Cat√©gorie")
     # categories par status
     #***********************
     
# DF pour stocker les data de groupby
        df_aggregated = df_clean.groupby(['category', 'status']).size().unstack(fill_value=0).reset_index()

# Calculer les pourcentages
        df_aggregated['total'] = df_aggregated['successful'] + df_aggregated['failed']
        df_aggregated['success_percentage'] = round((df_aggregated['successful'] / df_aggregated['total']) * 100,2)
        df_aggregated['failed_percentage'] = round((df_aggregated['failed'] / df_aggregated['total']) * 100,2)

# charger palette seaborn
        sns.set()

# R√©cup√©rer couleur par defaut de seaborn
        seaborn_palette = sns.color_palette()

# Convertir les couleurs en format hexad√©cimal
        color_discrete_map = {'successful': seaborn_palette[1], 'failed': seaborn_palette[0]}
        color_discrete_map_hex = {k: f'#{int(c[0]*255):02x}{int(c[1]*255):02x}{int(c[2]*255):02x}' for k, c in color_discrete_map.items()}


# Cr√©er graphique interactif avec Plotly Express
        fig2 = px.bar(df_aggregated, x='category', y=['successful', 'failed'],
              labels={'successful': 'Quantit√© de succ√®s', 'failed': 'Quantit√© d\'√©checs'},
              title='Quantit√© de succ√®s et d\'√©checs par cat√©gorie',
              barmode='group',
              hover_data={'success_percentage': ':.2f%', 'failed_percentage': ':.2f%'},
              color_discrete_map=color_discrete_map_hex)

# Afficher le graphique avec Streamlit
        st.plotly_chart(fig2)
        st.write("                                ")
        st.write("En conclusion, il est incorrect de g√©n√©raliser en affirmant qu'un plus grand nombre de campagnes entra√Æne automatiquement un plus grand nombre de r√©ussites, ou qu'un nombre moins √©lev√© de campagnes conduit √† un nombre de r√©ussite inf√©rieur. Chaque cat√©gorie de campagne pr√©sente ses propres caract√©ristiques et il est essentiel d'analyser les facteurs sp√©cifiques qui contribuent √† la r√©ussite d'une campagne dans chaque contexte")
    
    
    
    # test Anova
    #***************
    
        st.write("Test ANOVA")
        st.write("Ce test nous permettra d'analyser si la cat√©gorie de la campagne a une influence significative sur le nombre de backers qui soutiennent la campagne, ce qui pourrait contribuer √† expliquer les r√©sultats observ√©s")
        import statsmodels.api
# est-ce que la cat√©gorie a un effet significatif sur le nombre des backers de la campagne
        st.write("ùêª0: Pas d'effet significatif de la cat√©gorie sur le nombre de backers de la campagne")
        st.write("ùêª1: Il y a un effet significatif de la cat√©gorie de la campagne sur nombre de backers de la campagne")

        result = statsmodels.formula.api.ols('backers_count  ~ category', data=df_clean).fit()
        AnovaTable = statsmodels.api.stats.anova_lm(result)
        st.write(AnovaTable)
        st.write("Conclusion: p-valeur < ùõº (0.05), on conclut donc  une influence significative de cat√©gorie sur le nombre de backer")


    #Cat√©gories qui attirent plus de backers
    #*****************************************
        st.image("BplotByCat.jpg")
        st.write("Les cat√©gories qui enregistrent en moyenne ou en m√©diane le plus grand nombre de 'backers' sont: les jeux (games), les bandes dessin√©es (comics).")
        st.write("Les cat√©gories qui ont en moyenne ou en m√©diane le moins de 'backers' sont : les arts manuels (crafts), la nourriture (food), le journalisme (journalism) et la photographie (photography).")
        st.write("Les autres cat√©gories pr√©sentent des moyennes ou des m√©dianes de 'backers' qui ne montrent pas de grands √©carts entre eux.")
        st.write("La cat√©gorie technologie (technology) attire davantage de 'backers' , mais elle se distingue par un nombre de r√©ussite de campagnes relativement faible. En d'autres termes, bien qu'elle rassemble un grand nombre de 'backers', un nombre significatif de ses campagnes se soldent par un √©chec.")
 
#         Axe Finance
#***********************************
    elif page2 == page_names[1]:
        st.subheader("Axe Finance")

       
        sns.set_theme()

        
    # Votre fonction de comptage
        def comptage(test):
            suc = len(test[test['status'] == 'successful'])
            fail = len(test[test['status'] == 'failed'])
            return suc, fail

# Calculer les donn√©es de comptage
        comp1 = comptage(df_clean[df_clean['goal_usd'] <= 10])
        comp2 = comptage(df_clean[(10 < df_clean['goal_usd']) & (df_clean['goal_usd'] <= 100)])
        comp3 = comptage(df_clean[(100 < df_clean['goal_usd']) & (df_clean['goal_usd'] <= 1000)])
        comp4 = comptage(df_clean[(1000 < df_clean['goal_usd']) & (df_clean['goal_usd'] <= 10000)])
        comp5 = comptage(df_clean[(10000 < df_clean['goal_usd']) & (df_clean['goal_usd'] <= 100000)])
        comp6 = comptage(df_clean[(100000 < df_clean['goal_usd']) & (df_clean['goal_usd'] <= 1000000)])
        comp7 = comptage(df_clean[(1000000 < df_clean['goal_usd']) & (df_clean['goal_usd'] <= 10000000)])
        comp8 = comptage(df_clean[(10000000 < df_clean['goal_usd']) & (df_clean['goal_usd'] <= 100000000)])
        comp9 = comptage(df_clean[(100000000 < df_clean['goal_usd']) & (df_clean['goal_usd'] <= 1000000000)])
        comp = comptage(df_clean[df_clean['goal_usd'] > 1000000000])

# Convertir la palette de couleurs Seaborn en liste hexad√©cimale
        seaborn_colors = sns.color_palette("tab10", as_cmap=True).colors

# Cr√©er le graphique Plotly
        fig3 = px.bar(x=['<=10', '10-100', '100-1K', '1k-10K', '10K-100K', '100K-1M', '1M-10M', '10M-100M', '100M-1B'],
             y=[comp1[0], comp2[0], comp3[0], comp4[0], comp5[0], comp6[0], comp7[0], comp8[0], comp9[0]],
             labels={'y':'Count', 'x':'goal_usd'},
             title="Campagnes par tranche d'objectif en fonction du statut",
             barmode='group',
             color_discrete_sequence=['orange', 'blue'])
        
        fig3.add_bar(x=['<=10', '10-100', '100-1K', '1k-10K', '10K-100K', '100K-1M', '1M-10M', '10M-100M', '100M-1B'],
            y=[comp1[1], comp2[1], comp3[1], comp4[1], comp5[1], comp6[1], comp7[1], comp8[1], comp9[1]],
            name='failed',
            marker_color='blue')  # Utiliser la deuxi√®me couleur de la palette pour 'failed'

# Afficher le graphique √† l'aide de Streamlit
        st.plotly_chart(fig3)

        st.write("En conclusion les campagnes avec un financement entre 1K et 10K dollars affichent des perspectives plus √©lev√©es de r√©ussite. De plus, les campagnes sollicitant jusqu‚Äô√† 1M de dollars ont √©galement la possibilit√© de rencontrer du succ√®s. En revanche, les campagnes requ√©rant plus d‚Äô1M de dollars connaissent une diminution significative de leurs probabilit√©s de r√©ussite.")
        
#             Axe G√©ographique
#**************************************

    elif page2 == page_names[2]:    
        st.subheader("Axe G√©ographique")
        st.image("CountryQte.jpg")
        
        
# Charger la palette de couleur de Seaborn
        seaborn_palette = sns.color_palette()

# Convertir les couleurs de Seaborn en format hexad√©cimal
        def rgb_to_hex(rgb):
            return "#{:02x}{:02x}{:02x}".format(int(rgb[0] * 255), int(rgb[1] * 255), int(rgb[2] * 255))

        color_sequence = [rgb_to_hex(color) for color in seaborn_palette]

# Cr√©er le graphique avec Plotly Express
        fig4 = px.histogram(df_clean, x='country', color='status', title='Nombre des Campagnes par Pays selon le statut',
                   color_discrete_sequence=color_sequence)
        fig4.update_layout(barmode='group', xaxis_title='Pays', yaxis_title='Nombre de Campagnes')

# Afficher le graphique dans l'application Streamlit
        st.plotly_chart(fig4)
        st.write("Il est ind√©niable que les √âtats-Unis, le Royaume-Uni, le Canada et l'Australie repr√©sentent collecti-vement environ 80% du total de campagnes")
        st.write("possible raisons: Premi√®re plateforme de financement participatif, Taille du march√©, Langue commune, √âcosyst√®me entrepreneurial")

#             Axe Temporelle
#**************************************        
    elif page2 == page_names[3]:
        st.subheader("Axe Temporelle")
        # Charger la palette de couleur de Seaborn
        seaborn_palette = sns.color_palette()

# Convertir les couleurs de Seaborn en format hexad√©cimal
        def rgb_to_hex(rgb):
            return "#{:02x}{:02x}{:02x}".format(int(rgb[0] * 255), int(rgb[1] * 255), int(rgb[2] * 255))

        color_sequence = [rgb_to_hex(color) for color in seaborn_palette]

# Cr√©er le graphique avec Plotly Express
        fig5 = px.histogram(df_clean, x='duration', color='status', title='Nombre des Campagnes par  selon le statut',
                   color_discrete_sequence=color_sequence)
        fig5.update_layout(barmode='group', xaxis_title='Duration', yaxis_title='Nombre de Campagnes')
        st.plotly_chart(fig5)
        st.write("La grande majorit√© des campagnes ont une dur√©e de 30 jours. Cependant, lorsque la dur√©e est √©tendue √† 60 jours, le nombre de campagnes √©chou√©es d√©passent nettement celui des campagnes r√©ussies, au-del√† de cette dur√©e de 60 jours, la quantit√© des campagnes mises en ≈ìuvre diminue notablement.")

#***************************************************************************************************
#***************************************************************************************************
# PAGE 3 MODELISATION

#***************************************************************************************************
#***************************************************************************************************

elif  page == pages[3]:
    from sklearn.metrics import classification_report
#    from sklearn.metrics import confusion_matrix 
    st.title(" Mod√©lisation")
    df_clean = pd.read_csv("df_Cleaning.csv")
    # changement du type de colonne
    df_clean['launched_at'] = pd.to_datetime(df_clean['launched_at'])
     
    # 1.- Feature selection
    df_clean['day_launched'] = df_clean['launched_at'].dt.day
    colonnes =['id', 'currency','blurb','deadline','usd_pledged','creator_id','year_deadline','month_deadline','name', 'slug','launched_at','sub_category','city']

    df_clean = df_clean.drop(colonnes,axis=1)
    
    # 2.- S√©parer variable cible et variable explicatives
    #****************************************************

    # target variable cible( status: succesful, failed), feats  variables explicatives
    target = df_clean['status']# y

    feats = df_clean.drop('status', axis=1)# X

    # 3.- s√©parer les donn√©es en jeu de test et jeu d'entrainemment
    #**************************************************************

    X_train, X_test, y_train, y_test = train_test_split(feats, target, test_size=0.25, random_state = 42)


    num_train = X_train[['backers_count', 'blurb_length', 'goal_usd','duration','year_launched','month_launched','day_launched']]
    cat_train = X_train[['country','category'] ]

    num_test = X_test[['backers_count', 'blurb_length', 'goal_usd','duration','year_launched','month_launched','day_launched']]
    cat_test = X_test[['country','category']]   
    
    # 4.- Encodage 
    #*****************************************
    # 4.1 .- encodage des variables cat√©gorielles
    # *****************************************
    # (a) √† l'aide de OHE, encoder les variables cat√©gorielles
    # Le param√®tre drop permet d'√©viter le probl√®me de multicolin√©arit√©

    num_train = num_train.reset_index(drop=True)
    num_test = num_test.reset_index(drop=True)

    #from sklearn.preprocessing import OneHotEncoder

    ohe = OneHotEncoder( drop="first", sparse=False)

    colcat=['country','category']
    cat_train = pd.DataFrame(ohe.fit_transform(cat_train[colcat])) 
    cat_train.columns = ohe.get_feature_names_out(colcat)

    cat_test = pd.DataFrame(ohe.transform(cat_test[colcat]))
    cat_test.columns = ohe.get_feature_names_out(colcat)

    # (b)  reconstituer les jeu train et test en concatenant num_train avec cat_train et num_test avec cat_test
    #dfcat_train = pd.DataFrame(cat_train)
    X_train = pd.concat([num_train,cat_train],axis=1)

    X_test = pd.concat([num_test,cat_test],axis=1)

    # (c) afficher les dimensions des jeux reconstitu√©s
    # 4.2 .- encodage de variables num√©riques
    # *****************************************
    colonnes= [ 'blurb_length', 'duration','year_launched','month_launched','day_launched']

    scaler = StandardScaler()

    X_train[colonnes] = scaler.fit_transform(X_train[colonnes])

    X_test[colonnes] = scaler.transform(X_test[colonnes])
       
    # 4.3 .- encodage variable cible
    #*********************************
    #  Encoder les modalit√©s de la variable cible status √† l'aide d'un LABELENCODER
    # en estimant l'encodage sur le jeu d'entra√Ænement et en l'appliquant sur le jeu d'entra√Ænement et de test.

    # from sklearn.preprocessing import LabelEncoder

    le = LabelEncoder()

    y_train = le.fit_transform(y_train)

    y_test = le.transform(y_test)
    # 4.4.- encodage variables avec outliers
    #************************************

    from sklearn.preprocessing import RobustScaler

    # Soient X_train et X_test, les jeux, respectivement d'entra√Ænement et de test, des variables explicatives

    colonnes=['backers_count','goal_usd']

    scaler = RobustScaler()

    X_train[colonnes] = scaler.fit_transform(X_train[colonnes])

    X_test[colonnes]  = scaler.transform(X_test[colonnes] )
    
 #      importer les mod√®les entrain√©s et enregistr√©s en local
#*************************************************************  
   
    dtc1 = joblib.load("model_dtc")
    rl1 = joblib.load("model_rl")
    rf1 = joblib.load("model_rf")
   # knn1 = joblib.load("model_knn")
    gbc1 = joblib.load("model_gbc")
    
    y_pred_dtc = dtc1.predict(X_test)
    y_pred_rl1 = rl1.predict(X_test)
    y_pred_rf1 = rf1.predict(X_test)
    #y_pred_knn1 = knn1.predict(X_test)
    y_pred_gbc = gbc1.predict(X_test)
    
    mp='#### Meilleurs param√®tres '
    vs='#### Score'
    train= 'jeu entrainement: '
    test = 'jeu de test: '
    cr = '#### Classification Report'
    mc = "#### Matrice de Confusion"
    st.image("PerforSansHyper.jpg") 
    st.image("PerforAvecHyper.jpg")
    model_choisi = st.selectbox(label= "Mod√®le", options = ['DecisionTreeClassifier','Logistic Regression','Random Forest','Gradient Boosting Classifier'])
    if model_choisi == 'DecisionTreeClassifier':
        st.image("arbreDecision.jpg")
        st.write('#### Meilleurs param√®tres ') 
        st.write('{max_depth=8, min_samples_leaf=5}')
        # score train et test
        st.write('#### Score')
        st.write('jeu entrainement: ', dtc1.score(X_train,y_train))
        st.write('jeu de test: ', dtc1.score(X_test,y_test))
        y_pred = y_pred_dtc
        #st.write(classification_report (y_test, y_pred))
        st.write('#### Classification Report')
        st.text("Result:\n" + classification_report(y_test, y_pred))
        st.write("#### Matrice de Confusion")
        cmT = pd.crosstab(y_test, y_pred, rownames=['Classe r√©elle'], colnames=['Classe pr√©dite'])
        st.write(cmT)            
        # Graphique
        fig6, ax = plt.subplots()
        pd.Series(dtc1.feature_importances_, X_train.columns).sort_values(ascending=True).plot(kind='barh', ax=ax, figsize=(4, 8))
        ax.set_title('Decision Tree Feature Importances')
        ax.set_xlabel('Importance')
        ax.set_ylabel('Feature')
        st.pyplot(fig6)
        st.image("TreeFIPourcentage.png")
        st.write("constat:")
        st.write("Les variables 'backers_count' et 'goal_usd' √©mergent comme des √©l√©ments cruciaux dans la classification de notre arbre de d√©cision. Le nombre de contributeurs (backers) s'av√®re particuli√®rement d√©terminant pour le succ√®s d'une campagne. En outre, la variable 'goal_usd' se positionne en deuxi√®me place en termes d'importance. Son influence est clairement perceptible dans la structure de l'arbre, contribuant √† la formation de n≈ìuds et de feuilles caract√©ris√©s par une classe majoritaire de 'Sucessful'.")
        st.write("backers_count et goal_usd ont determin√© √† 99%  le status d'une campagne, les autres variables influence seulement √† 0.1%")
        st.write("Conclusion: le mod√®le de Decision Tree Classifier, nous donne des bonnes pr√©dictions")
        
    elif model_choisi == 'Logistic Regression':
        st.write(mp)  
        st.write("{C= 1, penalty='l2', solver= 'liblinear'}")
        st.write(vs)
        st.write(train, rl1.score(X_train,y_train))
        st.write(test, rl1.score(X_test,y_test))
        y_pred =y_pred_rl1
        st.write(cr)
        st.text("Result:\n" + classification_report(y_test, y_pred))
        st.write(mc)
        cmT = pd.crosstab(y_test, y_pred, rownames=['Classe r√©elle'], colnames=['Classe pr√©dite'])
        st.write(cmT)  
        # Graphique
        fig7, ax = plt.subplots()
        pd.Series(rl1.coef_[0], X_train.columns).sort_values(ascending=True).plot(kind='barh', figsize=(4,8));
        ax.set_title('Logistic Regression Feature Importances')
        ax.set_xlabel('Importance')
        ax.set_ylabel('Feature')
        st.pyplot(fig7)
        
        st.write("constat:")
        st.write("La variable 'goal_usd' ne semble pas jouer un r√¥le significatif dans la sortie du mod√®le, ce qui pourrait expliquer, par exemple, pourquoi certaines campagnes avec un objectif financier √©lev√© ne r√©ussissent pas n√©cessairement, ou pourquoi seulement un nombre limit√© de campagnes aboutissent √† un √©tat de 'Successful'. En revanche, il est √©vident que le nombre de contributeurs ('backer_count') joue un r√¥le tr√®s important dans la sortie du mod√®le")
        st.image("RocRL.jpg")
        st.write("Constat:")
        st.write("Si le taux de vrais positifs est √©gal √† 1 et le taux de faux positifs est √©gal √† 1, cela signifie que toutes les campagnes 'Failed' ont √©t√© mal pr√©dites. Si les taux de vrais positifs et de faux positifs sont tous deux √©gaux √† 0, cela indique que toutes les campagnes sont d√©clar√©es comme 'Failed'. Lorsque la courbe ROC se rapproche du point (0,1), cela sugg√®re que les campagnes 'Successful' et 'Failed' sont bien pr√©dites. Dans notre cas, un AUC de 0.97 correspond √† la proportion d'√©chantillons correctement class√©s. En d'autres termes, 97% des campagnes ont √©t√© correctement class√©es")
        st.write("Conclusion:")
        st.write(" Notre mod√®le de R√©gression logistique effectue d√©j√† des tr√®s bonnes pr√©dictions des campagnes 'Sucessful' et 'Failed'")      
        
        
    elif model_choisi == 'Random Forest':
        st.write(mp)
        st.write("{max_depth =14, min_samples_leaf= 5}")
        st.write(vs)
        st.write(train, rf1.score(X_train,y_train))
        st.write(test, rf1.score(X_test,y_test))
        y_pred = y_pred_rf1
        st.write(cr)
        st.text("Result:\n" + classification_report(y_test, y_pred))
        st.write(mc)
        cmT = pd.crosstab(y_test, y_pred, rownames=['Classe r√©elle'], colnames=['Classe pr√©dite'])
        st.write(cmT) 
        # graphique
        fig8, ax = plt.subplots()
        pd.Series(rf1.feature_importances_, X_train.columns).sort_values(ascending=True).plot(kind='barh', figsize=(4,8));
        ax.set_title('Random Forest Feature Importances')
        ax.set_xlabel('Importance')
        ax.set_ylabel('Feature')
        st.pyplot(fig8)
        st.write("consta: les variables 'backer_count' et 'goal_usd' semblent jouer un r√¥le significatif dans la sortie du mod√®le ")
        st.write("conclusion: Le mod√®le de Random Forest effectue de tr√®s bonnes pr√©dictions mais le nombre de Faux Positif est encore √©lev√©")
        
    elif model_choisi == 'Gradient Boosting Classifier':
        st.write("Gradient Boosting: C'est un ensemble de ¬´weak learners¬ª (algorithmes de faible performance) cr√©√©s les uns apr√®s les autres formant un ¬´ strong learner ¬ª (algorithme beaucoup plus efficace). Chaque ¬´ weak learner¬ª est entra√Æn√© pour corriger les erreurs des ¬´weak learners¬ª pr√©c√©dents. La Particularit√© de Gradient Boosting r√©side dans sa tentative de pr√©dire, √† chaque √©tape, les r√©sidus (√©cart entre la moyenne et la r√©alit√©). Les ¬´ weak learners ¬ª ont tous autant de poids dans le syst√®me de votation peu importe leur performance.")
        st.write(mp)
        st.write("{'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 250}")
        st.write(vs)
        st.write(train, gbc1.score(X_train,y_train))
        st.write(test, gbc1.score(X_test,y_test))
        y_pred = y_pred_gbc
        st.write(cr)
        st.text("Result:\n" + classification_report(y_test, y_pred))
        st.write(mc)
        cmT = pd.crosstab(y_test, y_pred, rownames=['Classe r√©elle'], colnames=['Classe pr√©dite'])
        st.write(cmT) 
        import shap
        explainer = shap.TreeExplainer(gbc1)
        shap_values = explainer.shap_values(X_test)
        #shap.summary_plot(shap_values, X_test, plot_type="bar")    
        # Create a SHAP summary plot using Streamlit
        st.set_option('deprecation.showPyplotGlobalUse', False)  # To avoid warning about pyplot use

# Plot the SHAP summary plot
        st.write("#### Importance moyenne des variables sur l'output du Gradient Boosting Classifier")
        shap.summary_plot(shap_values, X_test, plot_type="bar")

# Display the plot using Streamlit
        st.pyplot()
        st.write("### Participation de chaque variable dans la prediction final")
        shap.summary_plot(shap_values, X_test)
        st.pyplot()
        st.write("Les variables 'backer_count' et 'goal_usd' exercent une influence sur l'ensemble des pr√©dictions du mod√®le.")
        st.write("backer_count:")
        st.write("‚Ä¢ Une valeur plus faible ou basse de backer_count est associ√©e √† une valeur SHAP n√©gative, ce qui oriente la pr√©diction vers 0, indiquant ainsi un √©chec ou un statut 'failed'. ‚Ä¢ Certaines occurrences de valeurs basses de backer_count g√©n√®rent des valeurs SHAP positives, favorisant ainsi une pr√©diction de 1 (projet r√©ussi ou 'successful').‚Ä¢ √Ä mesure que la valeur de backer_count augmente, elle est associ√©e √† une valeur SHAP positive, renfor√ßant la pr√©diction de 1 (projet r√©ussi ou 'successful').")
        st.write("goal_usd: ")
        st.write("‚Ä¢	Une valeur plus √©lev√©e de goal_usd est associ√©e √† une valeur SHAP n√©gative, incitant √† pr√©dire 0, ce qui indique un √©chec ou un statut 'failed'. ‚Ä¢ √Ä l'inverse, une valeur plus faible ou basse de goal_usd est li√©e √† une valeur SHAP positive, encourageant ainsi la pr√©diction de 1, signifiant un projet r√©ussi ou 'successful'.")
   
    
    
#***************************************************************************************************
#***************************************************************************************************

# PAGE 4 APPLICATION

#***************************************************************************************************
#***************************************************************************************************
    
elif  page == pages[4]:
    
    
    st.write("### Testez la R√©ussite de votre campagne")

    df_clean = pd.read_csv("df_Cleaning.csv")
# changement du type de colonne
    df_clean['launched_at'] = pd.to_datetime(df_clean['launched_at'])
    #st.write(df_clean.dtypes)

# 1.- Feature selection
    df_clean['day_launched'] = df_clean['launched_at'].dt.day
    colonnes =['id', 'currency','blurb','deadline','usd_pledged','creator_id','year_deadline','month_deadline','name', 'slug','launched_at','sub_category','city']

    df_clean = df_clean.drop(colonnes,axis=1)

#***************************************************************************3

  # data interface ui
    goal = st.number_input('Saisissez un montant pour votre campagne',min_value = df_clean['goal_usd'].min()) #, max_value = df_clean['goal_usd'].max()
    st.write('Le montant saisi est: ', goal)
    
    dur = st.number_input('Saisissez le nombre de jours qui durera votre campagne', min_value = df_clean['duration'].min()) # , max_value = df_clean['duration'].max()
    st.write('Le montant saisi est:', dur)
   
    categ = st.selectbox(label= "Choisissez une Cat√©gorie", options =['food', 'publishing' ,'technology' ,'film & video' ,'games' ,'theater',

                                                                 'journalism' ,'music' ,'design', 'art' ,'crafts' ,'photography', 'fashion', 'comics' ,'dance'])
    st.write('La cat√©gorie saisi est: ', categ)
    
    bkT = int(df_clean['backers_count'].median())
    countryT = df_clean['country'].mode()[0]
    bLenT = int(df_clean['blurb_length'].median())
    yearT = int(df_clean['year_launched'].mean())
    monthT = int(df_clean['month_launched'].mean())
    dayT = int(df_clean['day_launched'].mean())
    
    dataSaisi = {'backers_count': [bkT] , 
                'country': [countryT] ,
                'status': [0],
                'category': [categ],
                'blurb_length': [bLenT],
                'goal_usd': [goal],
                'duration': [dur],
                'year_launched': [yearT],
                'month_launched': [monthT],
                'day_launched': [dayT]
                }

    dfSaisi = pd.DataFrame(data=dataSaisi)
    

# 2.- S√©parer variable cible et variable explicatives
#****************************************************

# target variable cible( status: succesful, failed), feats  variables explicatives
 #   target = dfSaisi['status']# y

    X_saisi = dfSaisi.drop('status', axis=1)# X

    
    # 3.- s√©parer les donn√©es en jeu de test et jeu d'entrainemment
#**************************************************************
    num_test = X_saisi[['backers_count', 'blurb_length', 'goal_usd','duration','year_launched','month_launched','day_launched']]
    cat_test = X_saisi[['country','category']]
    

# 4.- Encodage 
#*****************************************
# 4.1 .- encodage des variables cat√©gorielles
# *****************************************
# (a) √† l'aide de OHE, encoder les variables cat√©gorielles
# Le param√®tre drop permet d'√©viter le probl√®me de multicolin√©arit√©
# import ohe
    ohe = joblib.load('encoder_joblib')
    

    num_test = num_test.reset_index(drop=True)

    colcat=['country','category']
    cat_test = pd.DataFrame(ohe.transform(cat_test[colcat])) 
    cat_test.columns = ohe.get_feature_names_out(colcat)

    X_saisi = pd.concat([num_test,cat_test],axis=1)

    # 4.2 .- encodage de variables num√©riques
# *****************************************

    colonnes= [ 'blurb_length', 'duration','year_launched','month_launched','day_launched']

    scaler =joblib.load('scaler_joblib')
    X_saisi[colonnes] = scaler.transform(X_saisi[colonnes])
 

# 4.4.- encodage variables avec outliers
#************************************

    colonnes=['backers_count','goal_usd']

    rscaler = joblib.load('rscaler_joblib')

    X_saisi[colonnes] = rscaler.transform(X_saisi[colonnes])

        
    gbc1H = joblib.load("model_dtc")
    y_pred_gbc=gbc1H.predict(X_saisi)
    #st.write(y_pred_gbc)
    st.write("les probabilit√© en pourcentage de r√©ussite(1) ou d'echecs(0):")
    resultproba =(gbc1H.predict_proba(X_saisi))*100
    st.write(resultproba) 
    
elif  page == pages[5]:
    st.write("##### Challenges")
    st.write("‚Ä¢	Gestion des formats JSON au d√©but du projet")
    st.write("‚Ä¢	Modification du mentorat en cours d'avancement")
    st.write("‚Ä¢	Charge de travail cons√©quente pour une seule personne")
    st.write("‚Ä¢	Utilisation de biblioth√®ques qui ne font pas partie du programme du Data Analyst")
    st.write("##### Bilan")
    st.write("‚Ä¢	Tr√®s bonnes performances des mod√®les")
    st.write("‚Ä¢	Application approfondie des concepts de l'analyse de donn√©es et du machine learning, incluant les m√©triques et l'ajustement des hyperparam√®tres, pouss√©e jusqu'√† la recherche de l'interpr√©tabilit√©")
    st.write("##### Am√©liorations")
    st.write("‚Ä¢	Int√©gration du nom du projet dans les pr√©dictions en utilisant des techniques de traitement du langage naturel (NLP) ou des caract√©ristiques telles que la longueur du nom du projet")
    st.write("‚Ä¢	Introduction de tests statistiques suppl√©mentaires, par exemple, la v√©rification de la normalit√© des variables √† l‚Äôaide du test de Shapiro-Wilk")

# Ajout du texte de l'auteur
st.sidebar.title('Auteur')

# Ajout du lien LinkedIn
st.sidebar.markdown('[Maria Brenzikofer(Sehgelmeble)](https://www.linkedin.com/in/mariabrenzikofer/)')



